import streamlit as st
from google import genai
import os

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="æ­¦è¡“è¡“ç†ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", layout="wide")
st.title("ğŸ¥‹ å¿ƒå‹¢ä¼š è¡“ç†æ¢æ±‚ Bot")
st.caption("å‹ç¨½å¤ã®åŠ›ã€è¡“ç†ã«ã¤ã„ã¦å¿œç­”ã—ã¾ã™ã€‚")

# --- 1.5 ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ãƒªã‚¢é–¢æ•°ã®å®šç¾© ---
def clear_chat_history():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã€æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’é–‹å§‹ã™ã‚‹"""
    if "messages" in st.session_state:
        del st.session_state["messages"]
    if "chat" in st.session_state:
        del st.session_state["chat"]
    st.rerun()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ã‚’é…ç½®ï¼ˆã¾ãŸã¯ st.title ã®ä¸‹ãªã©ãŠå¥½ããªå ´æ‰€ã«ï¼‰
with st.sidebar:
    st.title("è¨­å®š")
    if st.button("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        clear_chat_history()

# --- 2. Gemini ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– ---
@st.cache_resource
def get_gemini_client():
    api_key = os.getenv("GEMINI_API_KEY") 
    # ä¸­ç•¥ï¼ˆAPIã‚­ãƒ¼å–å¾—å‡¦ç†ï¼‰
    
    # ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆï¼š'v1'ã‚’æŒ‡å®šã—ã¦ã€1.5ã‚’ç¢ºå®Ÿã«è¦‹ã¤ã‘å‡ºã—ã¾ã™
    from google.genai.types import HttpOptions
    client = genai.Client(
        api_key=api_key, 
        http_options=HttpOptions(api_version="v1")
    )
    return client

client = get_gemini_client()
MODEL_NAME = "gemini-1.5-flash"

# --- 3. çŸ¥è­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ– ---
if "messages" not in st.session_state:
    try:
        with open("budo_knowledge.txt", "r", encoding="utf-8") as f:
            knowledge_text = f.read()
    except FileNotFoundError:
        st.error("çŸ¥è­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        knowledge_text = ""

    system_instruction = f"""
    ã‚ãªãŸã¯ç‰çƒå¤ä¼ç©ºæ‰‹å¿ƒå‹¢ä¼šãªä»£è¡¨ã§ã™ã€‚
    ãƒ»ã€Œã€œãªã®ã§ã™ã€ã€Œã€œãªã®ã§ã™ã‚ˆã€ã€Œã€œã”ã–ã„ã¾ã™ã€ã¯ä¸€åˆ‡ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚
    ãƒ»ã€Œã€œã§ã™ã€ã€Œã€œã¾ã™ã€ã®å½¢ã«çµ±ä¸€ã—ã€æ–­å®šã‚’é¿ã‘ã‚‹å ´åˆã¯ã€Œã€œã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€ãªã©ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚
    ãƒ»ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ãƒ³ã‚’å°Šé‡ã—ã¤ã¤ã€ç¾ä»£çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„ã€Œã§ã™ã¾ã™èª¿ã€ã«ã—ã¦ãã ã•ã„ã€‚
    ä»¥ä¸‹ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«åŸºã¥ãã€ãƒ†ã‚­ã‚¹ãƒˆã®æ–‡ä½“ã«æ²¿ã£ãŸè¡¨ç¾ã‚’å¿ å®Ÿã«å®ˆã‚Šæ–‡æœ«ã®èªå°¾ãªã©ã‚‚ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ãƒ³ã«ãã®ã¾ã¾ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
ã€€ã€€ çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«ãªã„è³ªå•ã«ã¯ã€ã€Œãã®æƒ…å ±ã«ã¤ã„ã¦ã¯ã€ç¾åœ¨ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«å«ã¾ãŠã‚Šã¾ã›ã‚“ã€ã¨å¿œç­”ã—ã¦ãã ã•ã„ã€‚
    æœ€å¾Œã«è¿”ç­”ã®å†…å®¹ã®ç°¡å˜ãªã¾ã¨ã‚ã‚‚ã¤ã‘ã¦ãã ã•ã„ã€‚

    [æ­¦è¡“çŸ¥è­˜ãƒ™ãƒ¼ã‚¹]
    {knowledge_text}
    """
    
    config = genai.types.GenerateContentConfig(
        system_instruction=system_instruction
    )
    
    st.session_state.chat = client.chats.create(
        model=MODEL_NAME,
        config=config,
    )
    st.session_state.messages = [{"role": "model", "content": "ã‚ˆã†ã“ãã€è¡“ç†æ¢æ±‚ã®é“ã¸ã€‚æ­¦è¡“ã«é–¢ã™ã‚‹ã”è³ªå•ã¯ä½•ã§ã—ã‚‡ã†ã‹ï¼Ÿ"}]


# --- 4. æ—¢å­˜ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 5. ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¨AIå¿œç­”ã®å‡¦ç† ---
with st.form(key="chat_form", clear_on_submit=True):
    user_prompt = st.text_area(
        "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", 
        key="user_input_area",
        height=100,
        placeholder="æ­¦è¡“ã«é–¢ã™ã‚‹ã”è³ªå•ã‚’å…¥åŠ›ã—ã€ã€Œè³ªå•ã‚’é€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚"
    )
    submitted = st.form_submit_button("è³ªå•ã‚’é€ä¿¡")

if submitted and user_prompt:
    st.session_state.messages.append({"role": "user", "content": user_prompt})
    with st.chat_message("user"):
        st.markdown(user_prompt)

    try:
        response = st.session_state.chat.send_message(user_prompt)
        
        with st.chat_message("model"):
            st.markdown(response.text)
        st.session_state.messages.append({"role": "model", "content": response.text})
        
    except Exception as e:
        st.error(f"å¿œç­”ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")