import streamlit as st
from google import genai
import os

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="æ­¦è¡“è¡“ç†ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", layout="wide")
st.title("ğŸ¥‹ æ‰‹ã®æ¢ç©¶ è¡“ç†æ¢æ±‚ Bot")

# --- 2. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ– ---
@st.cache_resource
def get_client():
    # Secretsã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã‚€ã“ã¨ã§ã€å¤ã„ç’°å¢ƒå¤‰æ•°ã®å¹²æ¸‰ã‚’å®Œå…¨ã«é˜²ãã¾ã™
    try:
        # st.secrets.get ã§ã¯ãªãã€[] ã§ç›´æ¥æŒ‡å®šã—ã¦ç¢ºå®Ÿã«å–å¾—ã—ã¾ã™
        api_key = st.secrets["GEMINI_API_KEY"]
        return genai.Client(api_key=api_key)
    except Exception as e:
        st.error(f"Secretsã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

client = get_client()

# --- 3. ãƒãƒ£ãƒƒãƒˆç®¡ç† ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿
    try:
        with open("budo_knowledge.md", "r", encoding="utf-8") as f:
            knowledge = f.read()
    except:
        knowledge = ""

    # ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤ºï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šï¼‰
    st.session_state.sys_prompt = f"""
    ã‚ãªãŸã¯ç‰çƒå¤ä¼ç©ºæ‰‹å¿ƒå‹¢ä¼šã®è¡“ç†ã‚’æ“¬äººåŒ–ã—ãŸå­˜åœ¨ã§ã™ã€‚
    ãƒ»ã€Œèª¿æŸ»ã€ã‚„ã€Œãƒ¬ãƒãƒ¼ãƒˆã€ã¯ä¸è¦ã§ã™ã€‚
    ãƒ»æä¾›ã•ã‚ŒãŸã€å¿ƒå‹¢ä¼šçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã€‘ã®å†…å®¹ã®ã¿ã«åŸºã¥ã„ã¦ã€ä»Šã™ãç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚
    ãƒ»çŸ¥ã‚‰ãªã„ã“ã¨ã¯ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€ã¨ã ã‘ç­”ãˆã¦ãã ã•ã„ã€‚
    {knowledge}
    """
    st.session_state.messages.append({"role": "model", "content": "ã‚ˆã†ã“ãã€‚ã”è³ªå•ã‚’ã©ã†ãã€‚"})

# --- 4. å±¥æ­´è¡¨ç¤º ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- 5. å…¥åŠ›å‡¦ç† ---
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # é€ä¿¡ç”¨ã«ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤ºã‚’çµåˆ
    full_prompt = f"{st.session_state.sys_prompt}\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}"

    try:
        # ãƒ¢ãƒ‡ãƒ«åã‚’æœ€æ–°ã® Gemini 3 Flash Preview ã«å¤‰æ›´
        response = client.models.generate_content(
            model="gemini-2.0-flash", 
            contents=full_prompt
        )
        answer = response.text
        
        # --- ã“ã“ã‹ã‚‰è¿½åŠ ï¼šç”»é¢ã«å›ç­”ã‚’è¡¨ç¤ºã—ã€å±¥æ­´ã«ä¿å­˜ã™ã‚‹ ---
        with st.chat_message("model"):
            st.markdown(answer)
        st.session_state.messages.append({"role": "model", "content": answer})
        # --------------------------------------------------
        
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")