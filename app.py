import streamlit as st
from google import genai
import os

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="æ­¦è¡“è¡“ç†ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", layout="wide")
st.title("ğŸ¥‹ å¿ƒå‹¢ä¼š è¡“ç†æ¢æ±‚ Bot")
st.caption("å‹ç¨½å¤ã®åŠ›ã€è¡“ç†ã«ã¤ã„ã¦å¿œç­”ã—ã¾ã™ã€‚")

# --- 1.5 ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ãƒªã‚¢é–¢æ•°ã®å®šç¾© ---
def clear_chat_history():
    if "messages" in st.session_state:
        del st.session_state["messages"]
    if "chat" in st.session_state:
        del st.session_state["chat"]
    st.rerun()

with st.sidebar:
    st.title("è¨­å®š")
    if st.button("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        clear_chat_history()

# --- 2. Gemini ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– ---
@st.cache_resource
def get_gemini_client():
    api_key = os.getenv("GEMINI_API_KEY") 
    if not api_key:
        try:
            api_key = st.secrets["GEMINI_API_KEY"]
        except KeyError:
            st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            st.stop()
    
    # å®‰å®šç‰ˆã® v1 ã‚’ä½¿ç”¨
    client = genai.Client(api_key=api_key)
    return client

client = get_gemini_client()
MODEL_NAME = "gemini-1.5-flash"

# --- 3. ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ– ---
if "messages" not in st.session_state:
    try:
        with open("budo_knowledge.txt", "r", encoding="utf-8") as f:
            knowledge_text = f.read()
    except FileNotFoundError:
        knowledge_text = ""

    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã‚’ã€Œæœ€åˆã®æŒ‡ç¤ºã€ã¨ã—ã¦å®šç¾©
    initial_prompt = f"""
    ã‚ãªãŸã¯ç‰çƒå¤ä¼ç©ºæ‰‹å¿ƒå‹¢ä¼šã®ä»£è¡¨ã§ã™ã€‚
    ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã‚’å³å®ˆã—ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚

    ã€èªå°¾ã®ãƒ«ãƒ¼ãƒ«ã€‘
    ãƒ»ã€Œã€œãªã®ã§ã™ã€ã€Œã€œãªã®ã§ã™ã‚ˆã€ã€Œã€œã”ã–ã„ã¾ã™ã€ã¯ä¸€åˆ‡ä½¿ã‚ãšã€ã€Œã€œã§ã™ã€ã€Œã€œã¾ã™ã€ã«çµ±ä¸€ã—ã¦ãã ã•ã„ã€‚
    ãƒ»æ ¼èª¿é«˜ãã‚‚è¦ªã—ã¿ã‚„ã™ã„ä¸å¯§èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

    ã€å›ç­”ã®æŒ‡é‡ã€‘
    ãƒ»ä»¥ä¸‹ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«åŸºã¥ãã€èª å®Ÿã‹ã¤ç°¡æ½”ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚
    ãƒ»çŸ¥è­˜ã«ãªã„å ´åˆã¯ã€Œç¾åœ¨ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«å«ã¾ã‚Œã¦ãŠã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚
    ãƒ»æœ€å¾Œã«å†…å®¹ã®ç°¡å˜ãªã¾ã¨ã‚ã‚’ã¤ã‘ã¦ãã ã•ã„ã€‚

    [æ­¦è¡“çŸ¥è­˜ãƒ™ãƒ¼ã‚¹]
    {knowledge_text}
    """
    
    # ã‚¨ãƒ©ãƒ¼ã®å…ƒã«ãªã‚‹ config æŒ‡å®šã‚’é¿ã‘ã€ç©ºã®çŠ¶æ…‹ã§ãƒãƒ£ãƒƒãƒˆã‚’é–‹å§‹
    st.session_state.chat = client.chats.create(model=MODEL_NAME)
    
    # æœ€åˆã®æŒ‡ç¤ºã‚’AIã«é€ã‚Šã€è¨­å®šã‚’è¦šãˆã•ã›ã‚‹ï¼ˆç”»é¢ã«ã¯è¡¨ç¤ºã—ãªã„ï¼‰
    st.session_state.chat.send_message(initial_prompt)
    
    st.session_state.messages = [{"role": "model", "content": "ã‚ˆã†ã“ãã€å¿ƒå‹¢ä¼šã¸ã€‚æ­¦è¡“ã®è¡“ç†ã«ã¤ã„ã¦ã€ä½•ãªã‚Šã¨ãŠå°‹ã­ãã ã•ã„ã€‚"}]

# --- 4. å±¥æ­´è¡¨ç¤ºã¨å…¥åŠ›å‡¦ç† ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

with st.form(key="chat_form", clear_on_submit=True):
    user_prompt = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=100)
    submitted = st.form_submit_button("è³ªå•ã‚’é€ä¿¡")

if submitted and user_prompt:
    st.session_state.messages.append({"role": "user", "content": user_prompt})
    with st.chat_message("user"):
        st.markdown(user_prompt)

    try:
        response = st.session_state.chat.send_message(user_prompt)
        with st.chat_message("model"):
            st.markdown(response.text)
        st.session_state.messages.append({"role": "model", "content": response.text})
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã‚„ã‚Šç›´ã—ã¦ãã ã•ã„: {e}")